{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "NLP-SPAM detection_gjurcin.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gjurcin/nlp_classification/blob/main/NLP_SPAM_detection_gjurcin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9jdcbWr3Bg6"
      },
      "source": [
        "# Spam Detection\n",
        "\n",
        "The goal is to create a model that will detect if a given email is a SPAM or not.\n",
        "\n",
        "Dataset:\n",
        "https://drive.google.com/file/d/1b9HGiCd5KBppH8QG_20BDALIBguDngjU/view?usp=sharing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMfrdNT-3BhE"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN1gHm8e3BhN"
      },
      "source": [
        "## 1. Read the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lW-J9FE3BhO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "87f2a727-e4f9-412d-f8a9-143831a20311"
      },
      "source": [
        "path_to_text = 'datasets-spam.csv'\n",
        "data = pd.read_csv(path_to_text, encoding='latin-1')[['v1', 'v2']]\n",
        "\n",
        "# Creating the feature set and label set\n",
        "text = data['v2']\n",
        "label = data['v1']\n",
        "data[5:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1                                                 v2\n",
              "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
              "6   ham  Even my brother is not like to speak with me. ...\n",
              "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "8  spam  WINNER!! As a valued network customer you have...\n",
              "9  spam  Had your mobile 11 months or more? U R entitle..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFm_kC5wJDIQ"
      },
      "source": [
        "Print the distribution of the data (number of positive-spam vs negative-ham)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mumC3fMr3Bhf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1903b1e0-fd18-4fd1-db2d-8ca4ec2b8ca1"
      },
      "source": [
        "data.v1.hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc6ce434748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KV64U_J3Bhg"
      },
      "source": [
        "## 2. Preprocess the data\n",
        "\n",
        "Use NLTK when needed\n",
        "- covert to lower letters\n",
        "- remove punctuation\n",
        "- tokenization\n",
        "- stop-words removal \n",
        "- lemmatization (use also Part of Speech tagger)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2kaIFWLLyt2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smTxq9lxKieg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac8a239-efa9-436d-ae6f-a5710b5af629"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "nltk.download('stopwords')\n",
        "stopwords_ = stopwords.words('english')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bJWaU1bi4JO"
      },
      "source": [
        "text_preprocessed = []\n",
        "for sentence in text:\n",
        "    #sentence lower\n",
        "    sentence = sentence.lower()\n",
        "    #string punct\n",
        "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "    #tokenize\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    # stop-words\n",
        "    tokens_stop_words = []\n",
        "    for token in tokens:\n",
        "      if token not in stopwords_:\n",
        "        tokens_stop_words.append(token)\n",
        "    # Lemmatization\n",
        "    tokens_lemma = []\n",
        "    for token in tokens_stop_words:\n",
        "      tokens_lemma.append(wnl.lemmatize(token, get_wordnet_pos(nltk.pos_tag([token])[0][1])))\n",
        "    final = ' '.join(tokens_lemma)\n",
        "    text_preprocessed.append(final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CoBoc_7xIn70",
        "outputId": "7560ea82-aa0e-44bf-92a8-83ba644cc5a0"
      },
      "source": [
        "text[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EksdP8hjBIy",
        "outputId": "5b8f78e9-0779-4655-c45c-60481f38da23"
      },
      "source": [
        "len(text_preprocessed),len(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 5572)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVE_fHzCKnCf"
      },
      "source": [
        "## 3. Count Vecotrizer model\n",
        "\n",
        "- use Count Vectorizer to create the feature vectors\n",
        "- Separate the data in train and test (the first 70% are train, the rest 30% are test)\n",
        "- Train three models: Logistic Regression\n",
        "- Evaluate the model on the test data (calculate: accuracy, precision, recall and F1-score for each class, and the confusion matrix)\n",
        "\n",
        "*Note: you will have to covert the labels from strings to binary - using the LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a931tOzt3Bhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f00753-0993-434d-a4aa-0bd489789d76"
      },
      "source": [
        "train_ratio= int(len(text)*0.7)\n",
        "trainX, testX =text_preprocessed[:train_ratio], text_preprocessed[train_ratio:]\n",
        "trainY, testY =label[:train_ratio], label[train_ratio:]\n",
        "len(trainX), len(testX) ,len(trainY), len(testY)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3900, 1672, 3900, 1672)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALEQO36ojcfR",
        "outputId": "2ac28231-251a-4a80-afd1-1f8464c4cd76"
      },
      "source": [
        "#encode lables (0-ham, 1-spam)\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "trainY= le.fit_transform(trainY)\n",
        "testY = le.fit_transform(testY)\n",
        "trainY.shape,testY.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3900,), (1672,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gm9REAIJdZw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "uAG7dWndlZg4",
        "outputId": "579c6e04-7f95-4d68-b3b5-c631938a2f45"
      },
      "source": [
        "plt.hist(trainY)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1IiaO77j5oj",
        "outputId": "403302f1-fd99-474b-c1bc-7a6855335aef"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Count Vectors as features\n",
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(max_features=5000)\n",
        "count_vect.fit(text_preprocessed)\n",
        "\n",
        "# transform the training and test data using count vectorizer object\n",
        "trainX_vec = count_vect.transform(trainX)\n",
        "testX_vec = count_vect.transform(testX)\n",
        "trainX_vec.shape,testX_vec.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3900, 5000), (1672, 5000))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql5aErkBJn1v",
        "outputId": "fee8f815-c5cd-40d2-ae62-03da19a0df02"
      },
      "source": [
        "trainX_vec[0], trainX[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<1x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
              " \twith 12 stored elements in Compressed Sparse Row format>,\n",
              " 'go jurong point crazy available bugis n great world la e buffet cine get amore wat')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFDTMSFCkkwZ",
        "outputId": "1b2d4083-3a8f-47a6-94c5-dcf4addd7041"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "\n",
        "#create an instance of the model\n",
        "lr_model = LogisticRegression(random_state=7)\n",
        "#train the model\n",
        "lr_model.fit(trainX_vec, trainY)\n",
        "\n",
        "#predict test data\n",
        "pred_test = lr_model.predict(testX_vec)\n",
        "\n",
        "#print evaluation metrics \n",
        "print(classification_report(testY,pred_test))\n",
        "confusion_matrix(testY,pred_test)\n",
        "print(\"Accuracy:\",accuracy_score(testY, pred_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      1444\n",
            "           1       0.99      0.84      0.91       228\n",
            "\n",
            "    accuracy                           0.98      1672\n",
            "   macro avg       0.98      0.92      0.95      1672\n",
            "weighted avg       0.98      0.98      0.98      1672\n",
            "\n",
            "Accuracy: 0.9772727272727273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YblTmMwgMcAJ"
      },
      "source": [
        "## 4. TF-IDF model\n",
        "\n",
        "- use TfidfVectorizer to create the feature vectors\n",
        "- Separate the data in train and test (the first 70% are train, the rest 30% are test)\n",
        "- Train three models: Logistic Regression\n",
        "- Evaluate the model on the test data (calculate: accuracy, precision, recall and F1-score for each class, and the confusion matrix)\n",
        "\n",
        "*Note: you will have to covert the labels from strings to binary - using the LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVEqZ4X_3Bhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6165fb2-1e59-43e8-85d9-03d27108fa53"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=5000) \n",
        "tfidf.fit(text)\n",
        "\n",
        "X_train_tfidf = tfidf.transform(trainX)\n",
        "X_test_tfidf = tfidf.transform(testX)\n",
        "\n",
        "X_train_tfidf.shape, X_test_tfidf.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3900, 5000), (1672, 5000))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVGdfHk9mTfl",
        "outputId": "e8f35274-9b7c-4de3-f8ea-5ba681955355"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model_tf = LogisticRegression(random_state=0)\n",
        "lr_model_tf.fit(X_train_tfidf, trainY)\n",
        "pred_test_tf = lr_model_tf.predict(X_test_tfidf)\n",
        "\n",
        "#print evaluation metrics \n",
        "print(classification_report(testY,pred_test_tf))\n",
        "print(confusion_matrix(testY,pred_test_tf))\n",
        "print(\"Accuracy:\",accuracy_score(testY, pred_test_tf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97      1444\n",
            "           1       0.97      0.68      0.80       228\n",
            "\n",
            "    accuracy                           0.95      1672\n",
            "   macro avg       0.96      0.84      0.89      1672\n",
            "weighted avg       0.95      0.95      0.95      1672\n",
            "\n",
            "[[1440    4]\n",
            " [  74  154]]\n",
            "Accuracy: 0.9533492822966507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJnXBXFZMsTf"
      },
      "source": [
        "## 5. WordEmbeddings model\n",
        "\n",
        "In additioan to the previous pre-processing steps, we need to:\n",
        "- Truncate and pad the input sequences so that they are all the same length for modeling, size = 30 (use sequence.pad_sequences)\n",
        "- Train Keras Sequential model with: Embedding layer (50 units), LSTM layer (50 units), Dense layer (1 unit). \n",
        "  - Create one model with RELU, another with Sigmoid\n",
        "- Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMXc-S-MnG0w",
        "outputId": "82307729-924c-48dd-f293-1aef210fbcd8"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer #similar to the CountVectorizer and TfIDF from keras\n",
        "\n",
        "#The word embedding layer expects input sequences to be comprised of integers.\n",
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(text_preprocessed)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(text_preprocessed)\n",
        "len(sequences),len(sequences[0]),len(sequences[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 16, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OpeXpOfHMcF2",
        "outputId": "b68a67d7-d3dc-4ec7-ead5-53b1f3e1eca4"
      },
      "source": [
        "text_preprocessed[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ok lar joking wif u oni'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f43WjYYYMeXa",
        "outputId": "09067d9a-93f6-4756-d875-e7d0a42b5de5"
      },
      "source": [
        "len(sequences[0]),len(sequences[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSYYDqy0nW9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb9b9cf-7d9f-470e-dc07-928e91be036e"
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'u': 1,\n",
              " 'get': 2,\n",
              " 'call': 3,\n",
              " 'go': 4,\n",
              " '2': 5,\n",
              " 'im': 6,\n",
              " 'ur': 7,\n",
              " 'come': 8,\n",
              " '4': 9,\n",
              " 'dont': 10,\n",
              " 'ok': 11,\n",
              " 'ampltampgt': 12,\n",
              " 'free': 13,\n",
              " 'know': 14,\n",
              " 'like': 15,\n",
              " 'want': 16,\n",
              " 'day': 17,\n",
              " 'ill': 18,\n",
              " 'good': 19,\n",
              " 'time': 20,\n",
              " 'love': 21,\n",
              " 'say': 22,\n",
              " 'text': 23,\n",
              " 'send': 24,\n",
              " 'need': 25,\n",
              " 'see': 26,\n",
              " 'take': 27,\n",
              " 'one': 28,\n",
              " 'make': 29,\n",
              " 'well': 30,\n",
              " 'today': 31,\n",
              " 'think': 32,\n",
              " 'r': 33,\n",
              " 'home': 34,\n",
              " 'txt': 35,\n",
              " 'lor': 36,\n",
              " 'reply': 37,\n",
              " 'stop': 38,\n",
              " 'tell': 39,\n",
              " 'sorry': 40,\n",
              " 'still': 41,\n",
              " 'back': 42,\n",
              " 'mobile': 43,\n",
              " 'n': 44,\n",
              " 'phone': 45,\n",
              " 'new': 46,\n",
              " 'work': 47,\n",
              " 'later': 48,\n",
              " 'week': 49,\n",
              " 'da': 50,\n",
              " 'hi': 51,\n",
              " 'please': 52,\n",
              " 'ask': 53,\n",
              " 'miss': 54,\n",
              " 'give': 55,\n",
              " 'cant': 56,\n",
              " 'ã\\x8c': 57,\n",
              " 'night': 58,\n",
              " 'claim': 59,\n",
              " 'wait': 60,\n",
              " 'thing': 61,\n",
              " 'great': 62,\n",
              " 'try': 63,\n",
              " 'much': 64,\n",
              " 'oh': 65,\n",
              " 'hey': 66,\n",
              " 'dear': 67,\n",
              " 'pls': 68,\n",
              " 'message': 69,\n",
              " 'number': 70,\n",
              " 'amp': 71,\n",
              " 'na': 72,\n",
              " 'happy': 73,\n",
              " 'friend': 74,\n",
              " 'hope': 75,\n",
              " 'way': 76,\n",
              " 'wat': 77,\n",
              " 'late': 78,\n",
              " 'prize': 79,\n",
              " 'right': 80,\n",
              " 'feel': 81,\n",
              " 'thats': 82,\n",
              " 'msg': 83,\n",
              " 'wan': 84,\n",
              " 'c': 85,\n",
              " 'let': 86,\n",
              " 'already': 87,\n",
              " 'tomorrow': 88,\n",
              " 'even': 89,\n",
              " 'yes': 90,\n",
              " 'really': 91,\n",
              " 'yeah': 92,\n",
              " 'min': 93,\n",
              " 'e': 94,\n",
              " '1': 95,\n",
              " 'babe': 96,\n",
              " 'co': 97,\n",
              " 'pick': 98,\n",
              " 'ampamp': 99,\n",
              " 'win': 100,\n",
              " 'life': 101,\n",
              " 'meet': 102,\n",
              " 'last': 103,\n",
              " 'didnt': 104,\n",
              " 'morning': 105,\n",
              " 'service': 106,\n",
              " 'would': 107,\n",
              " 'keep': 108,\n",
              " 'find': 109,\n",
              " 'year': 110,\n",
              " 'contact': 111,\n",
              " 'ive': 112,\n",
              " 'cash': 113,\n",
              " 'thanks': 114,\n",
              " 'leave': 115,\n",
              " 'sleep': 116,\n",
              " 'care': 117,\n",
              " 'lol': 118,\n",
              " 'anything': 119,\n",
              " 'tone': 120,\n",
              " 'look': 121,\n",
              " 'every': 122,\n",
              " 'k': 123,\n",
              " 'sure': 124,\n",
              " 'smile': 125,\n",
              " 'also': 126,\n",
              " 'wish': 127,\n",
              " 'watch': 128,\n",
              " 'start': 129,\n",
              " 'show': 130,\n",
              " '3': 131,\n",
              " 'use': 132,\n",
              " 'nokia': 133,\n",
              " 'something': 134,\n",
              " 'sent': 135,\n",
              " 'finish': 136,\n",
              " 'award': 137,\n",
              " 'end': 138,\n",
              " 'urgent': 139,\n",
              " 'b': 140,\n",
              " 'place': 141,\n",
              " 'buy': 142,\n",
              " 'next': 143,\n",
              " 'first': 144,\n",
              " 'guy': 145,\n",
              " 'around': 146,\n",
              " 'talk': 147,\n",
              " 'tonight': 148,\n",
              " 'customer': 149,\n",
              " 'could': 150,\n",
              " 'someone': 151,\n",
              " 'gon': 152,\n",
              " 'soon': 153,\n",
              " 'chat': 154,\n",
              " 'many': 155,\n",
              " 'per': 156,\n",
              " 'help': 157,\n",
              " 'nice': 158,\n",
              " 'money': 159,\n",
              " 'word': 160,\n",
              " 'always': 161,\n",
              " 'ya': 162,\n",
              " 'dun': 163,\n",
              " 'wont': 164,\n",
              " 'v': 165,\n",
              " 'youre': 166,\n",
              " 'gud': 167,\n",
              " 'told': 168,\n",
              " 'name': 169,\n",
              " 'ã\\x8cã\\x8f': 170,\n",
              " 'hour': 171,\n",
              " 'people': 172,\n",
              " 'lot': 173,\n",
              " 'minute': 174,\n",
              " '16': 175,\n",
              " 'reach': 176,\n",
              " 'girl': 177,\n",
              " 'guaranteed': 178,\n",
              " 'yet': 179,\n",
              " 'thk': 180,\n",
              " 'plan': 181,\n",
              " 'x': 182,\n",
              " 'do': 183,\n",
              " 'hello': 184,\n",
              " 'check': 185,\n",
              " 'eat': 186,\n",
              " 'live': 187,\n",
              " 'thought': 188,\n",
              " 'person': 189,\n",
              " 'haha': 190,\n",
              " 'class': 191,\n",
              " 'fuck': 192,\n",
              " 'may': 193,\n",
              " 'receive': 194,\n",
              " 'fine': 195,\n",
              " 'offer': 196,\n",
              " 'mean': 197,\n",
              " 'havent': 198,\n",
              " 'line': 199,\n",
              " 'stuff': 200,\n",
              " 'lunch': 201,\n",
              " 'man': 202,\n",
              " 'job': 203,\n",
              " 'car': 204,\n",
              " 'hows': 205,\n",
              " 'bit': 206,\n",
              " 'best': 207,\n",
              " 'draw': 208,\n",
              " 'holiday': 209,\n",
              " 'big': 210,\n",
              " 'heart': 211,\n",
              " 'enjoy': 212,\n",
              " 'month': 213,\n",
              " 'yup': 214,\n",
              " 'never': 215,\n",
              " 'play': 216,\n",
              " 'special': 217,\n",
              " 'meeting': 218,\n",
              " 'happen': 219,\n",
              " '18': 220,\n",
              " '5': 221,\n",
              " 'sm': 222,\n",
              " 'long': 223,\n",
              " 'drive': 224,\n",
              " 'guess': 225,\n",
              " 'account': 226,\n",
              " 'dat': 227,\n",
              " 'mind': 228,\n",
              " 'chance': 229,\n",
              " 'cool': 230,\n",
              " 'ready': 231,\n",
              " 'problem': 232,\n",
              " 'god': 233,\n",
              " 'cost': 234,\n",
              " 'weekend': 235,\n",
              " 'bad': 236,\n",
              " 'pay': 237,\n",
              " 'room': 238,\n",
              " 'lar': 239,\n",
              " 'date': 240,\n",
              " 'half': 241,\n",
              " 'nothing': 242,\n",
              " 'book': 243,\n",
              " 'game': 244,\n",
              " 'lose': 245,\n",
              " '1st': 246,\n",
              " 'yo': 247,\n",
              " 'another': 248,\n",
              " 'voucher': 249,\n",
              " 'world': 250,\n",
              " 'camera': 251,\n",
              " 'charge': 252,\n",
              " 'real': 253,\n",
              " 'birthday': 254,\n",
              " 'landline': 255,\n",
              " 'house': 256,\n",
              " 'boy': 257,\n",
              " 'easy': 258,\n",
              " 'shit': 259,\n",
              " 'kiss': 260,\n",
              " 'put': 261,\n",
              " 'speak': 262,\n",
              " 'dinner': 263,\n",
              " 'sweet': 264,\n",
              " 'ã¥â£1000': 265,\n",
              " 'join': 266,\n",
              " 'sir': 267,\n",
              " 'liao': 268,\n",
              " 'jus': 269,\n",
              " 'box': 270,\n",
              " 'ever': 271,\n",
              " 'early': 272,\n",
              " 'remember': 273,\n",
              " '150ppm': 274,\n",
              " 'question': 275,\n",
              " 'luv': 276,\n",
              " 'stay': 277,\n",
              " 'might': 278,\n",
              " 'quite': 279,\n",
              " 'point': 280,\n",
              " 'collect': 281,\n",
              " 'change': 282,\n",
              " 'aight': 283,\n",
              " 'whats': 284,\n",
              " 'probably': 285,\n",
              " 'pic': 286,\n",
              " 'apply': 287,\n",
              " 'id': 288,\n",
              " 'fun': 289,\n",
              " 'run': 290,\n",
              " 'he': 291,\n",
              " 'part': 292,\n",
              " 'hear': 293,\n",
              " 'pa': 294,\n",
              " 'bed': 295,\n",
              " 'hurt': 296,\n",
              " 'worry': 297,\n",
              " 'rate': 298,\n",
              " 'answer': 299,\n",
              " 'po': 300,\n",
              " 'video': 301,\n",
              " 'baby': 302,\n",
              " 'two': 303,\n",
              " 'actually': 304,\n",
              " 'den': 305,\n",
              " 'princess': 306,\n",
              " '6': 307,\n",
              " 'xxx': 308,\n",
              " 'network': 309,\n",
              " 'select': 310,\n",
              " 'bus': 311,\n",
              " 'maybe': 312,\n",
              " 'forgot': 313,\n",
              " 'ã¥â£2000': 314,\n",
              " 'thanx': 315,\n",
              " 'wake': 316,\n",
              " 'shopping': 317,\n",
              " 'dunno': 318,\n",
              " 'orange': 319,\n",
              " 'code': 320,\n",
              " 'left': 321,\n",
              " '2nd': 322,\n",
              " 'dis': 323,\n",
              " 'ah': 324,\n",
              " 'little': 325,\n",
              " 'walk': 326,\n",
              " 'bring': 327,\n",
              " 'dad': 328,\n",
              " 'enough': 329,\n",
              " 'there': 330,\n",
              " 'school': 331,\n",
              " 'leh': 332,\n",
              " 'face': 333,\n",
              " 'everything': 334,\n",
              " 'sat': 335,\n",
              " 'shall': 336,\n",
              " 'shes': 337,\n",
              " 'mate': 338,\n",
              " 'pound': 339,\n",
              " 'thank': 340,\n",
              " 'afternoon': 341,\n",
              " 'without': 342,\n",
              " 'tv': 343,\n",
              " 'xmas': 344,\n",
              " 'tmr': 345,\n",
              " 'sound': 346,\n",
              " 'movie': 347,\n",
              " '7': 348,\n",
              " 'gift': 349,\n",
              " 'await': 350,\n",
              " 'wif': 351,\n",
              " 'ã¥â£150': 352,\n",
              " 'credit': 353,\n",
              " 'decide': 354,\n",
              " 'since': 355,\n",
              " 'test': 356,\n",
              " 'anyway': 357,\n",
              " 'must': 358,\n",
              " 'mail': 359,\n",
              " 'sexy': 360,\n",
              " 'dream': 361,\n",
              " 'post': 362,\n",
              " 'detail': 363,\n",
              " 'town': 364,\n",
              " 'entry': 365,\n",
              " 'though': 366,\n",
              " '9': 367,\n",
              " 'doesnt': 368,\n",
              " 'ringtone': 369,\n",
              " 'uk': 370,\n",
              " 'lesson': 371,\n",
              " 'abt': 372,\n",
              " 'okay': 373,\n",
              " 'able': 374,\n",
              " 'hav': 375,\n",
              " 'important': 376,\n",
              " 'collection': 377,\n",
              " 'pain': 378,\n",
              " 'mob': 379,\n",
              " 'price': 380,\n",
              " 'juz': 381,\n",
              " 'order': 382,\n",
              " 'til': 383,\n",
              " '500': 384,\n",
              " 'true': 385,\n",
              " 'plz': 386,\n",
              " 'office': 387,\n",
              " 'tampcs': 388,\n",
              " 'away': 389,\n",
              " 'plus': 390,\n",
              " 'update': 391,\n",
              " 'till': 392,\n",
              " 'hair': 393,\n",
              " 'wen': 394,\n",
              " 'else': 395,\n",
              " 'enter': 396,\n",
              " 'weekly': 397,\n",
              " 'wot': 398,\n",
              " 'dude': 399,\n",
              " 'attempt': 400,\n",
              " 'de': 401,\n",
              " 'wonder': 402,\n",
              " 'drop': 403,\n",
              " 'valid': 404,\n",
              " 'colour': 405,\n",
              " 'alright': 406,\n",
              " 'saw': 407,\n",
              " 'yesterday': 408,\n",
              " 'double': 409,\n",
              " 'trip': 410,\n",
              " 'wk': 411,\n",
              " 'food': 412,\n",
              " 'top': 413,\n",
              " 'bt': 414,\n",
              " 'haf': 415,\n",
              " 'hand': 416,\n",
              " 'ampltdecimalampgt': 417,\n",
              " 'oso': 418,\n",
              " 'music': 419,\n",
              " '150p': 420,\n",
              " 'bore': 421,\n",
              " 'lei': 422,\n",
              " 'set': 423,\n",
              " 'search': 424,\n",
              " 'invite': 425,\n",
              " 'delivery': 426,\n",
              " 'close': 427,\n",
              " 'yr': 428,\n",
              " 'smoke': 429,\n",
              " 'si': 430,\n",
              " 'head': 431,\n",
              " 'hot': 432,\n",
              " 'friendship': 433,\n",
              " 'drink': 434,\n",
              " 'either': 435,\n",
              " 'sch': 436,\n",
              " 'ã¥â£100': 437,\n",
              " 'wife': 438,\n",
              " 'online': 439,\n",
              " 'ard': 440,\n",
              " 'mom': 441,\n",
              " 'second': 442,\n",
              " 'bonus': 443,\n",
              " 'cause': 444,\n",
              " 'address': 445,\n",
              " 'player': 446,\n",
              " 'story': 447,\n",
              " 'nite': 448,\n",
              " 'g': 449,\n",
              " 'hold': 450,\n",
              " 'wid': 451,\n",
              " 'full': 452,\n",
              " 'tot': 453,\n",
              " 'sae': 454,\n",
              " 'family': 455,\n",
              " 'together': 456,\n",
              " 'goin': 457,\n",
              " '8007': 458,\n",
              " 'sad': 459,\n",
              " 'brother': 460,\n",
              " 'ã¥â£5000': 461,\n",
              " 'old': 462,\n",
              " 'match': 463,\n",
              " 'believe': 464,\n",
              " 'touch': 465,\n",
              " 'noe': 466,\n",
              " 'ring': 467,\n",
              " 'huh': 468,\n",
              " 'land': 469,\n",
              " 'beautiful': 470,\n",
              " 'email': 471,\n",
              " 'treat': 472,\n",
              " 'aft': 473,\n",
              " 'busy': 474,\n",
              " 'private': 475,\n",
              " 'dog': 476,\n",
              " 'content': 477,\n",
              " 'hop': 478,\n",
              " 'study': 479,\n",
              " 'gr8': 480,\n",
              " 'awesome': 481,\n",
              " 'break': 482,\n",
              " 'shop': 483,\n",
              " 'die': 484,\n",
              " 'coz': 485,\n",
              " 'club': 486,\n",
              " '86688': 487,\n",
              " 'okie': 488,\n",
              " 'eve': 489,\n",
              " 'ã¥â£500': 490,\n",
              " 'listen': 491,\n",
              " 'mum': 492,\n",
              " 'rite': 493,\n",
              " 'final': 494,\n",
              " 'caller': 495,\n",
              " 'forget': 496,\n",
              " 'congrats': 497,\n",
              " 'move': 498,\n",
              " 'statement': 499,\n",
              " 'age': 500,\n",
              " 'open': 501,\n",
              " 'everyone': 502,\n",
              " 'fancy': 503,\n",
              " 'company': 504,\n",
              " 'wil': 505,\n",
              " 'angry': 506,\n",
              " '750': 507,\n",
              " 'unsubscribe': 508,\n",
              " 'choose': 509,\n",
              " 'card': 510,\n",
              " 'sister': 511,\n",
              " 'valentine': 512,\n",
              " 'reason': 513,\n",
              " 'simple': 514,\n",
              " 'neva': 515,\n",
              " 'pub': 516,\n",
              " 'laugh': 517,\n",
              " 'sell': 518,\n",
              " 'value': 519,\n",
              " '100': 520,\n",
              " 'news': 521,\n",
              " 'tho': 522,\n",
              " 'tomo': 523,\n",
              " 'seem': 524,\n",
              " 'lucky': 525,\n",
              " 'ta': 526,\n",
              " 'isnt': 527,\n",
              " '12hrs': 528,\n",
              " 'expires': 529,\n",
              " 'bank': 530,\n",
              " 'worth': 531,\n",
              " 'found': 532,\n",
              " 'sort': 533,\n",
              " 'poly': 534,\n",
              " 'mine': 535,\n",
              " 'fast': 536,\n",
              " 'whatever': 537,\n",
              " 'knw': 538,\n",
              " 'anyone': 539,\n",
              " 'parent': 540,\n",
              " 'alone': 541,\n",
              " 'auction': 542,\n",
              " 'available': 543,\n",
              " 'winner': 544,\n",
              " 'pobox': 545,\n",
              " 'ha': 546,\n",
              " 'smth': 547,\n",
              " 'saturday': 548,\n",
              " '08000930705': 549,\n",
              " 'song': 550,\n",
              " 'ticket': 551,\n",
              " 'prob': 552,\n",
              " 'uncle': 553,\n",
              " 'unredeemed': 554,\n",
              " 'identifier': 555,\n",
              " 'type': 556,\n",
              " 'hard': 557,\n",
              " 'frnd': 558,\n",
              " 'log': 559,\n",
              " 'boytoy': 560,\n",
              " 'exam': 561,\n",
              " 'secret': 562,\n",
              " 'anytime': 563,\n",
              " 'far': 564,\n",
              " 'mobileupd8': 565,\n",
              " 'ã¥â£250': 566,\n",
              " 'welcome': 567,\n",
              " 'kind': 568,\n",
              " 'visit': 569,\n",
              " '8': 570,\n",
              " 'sun': 571,\n",
              " 'sit': 572,\n",
              " 'w': 573,\n",
              " 'add': 574,\n",
              " 'gd': 575,\n",
              " 'party': 576,\n",
              " 'crazy': 577,\n",
              " 'tampc': 578,\n",
              " 'wonderful': 579,\n",
              " 'camcorder': 580,\n",
              " 'cut': 581,\n",
              " 'follow': 582,\n",
              " 'save': 583,\n",
              " 'download': 584,\n",
              " 'rain': 585,\n",
              " 'hit': 586,\n",
              " 'bday': 587,\n",
              " 'operator': 588,\n",
              " 'friday': 589,\n",
              " 'mu': 590,\n",
              " 'nt': 591,\n",
              " 'ltd': 592,\n",
              " 'wit': 593,\n",
              " 'carlos': 594,\n",
              " 'finally': 595,\n",
              " 'college': 596,\n",
              " 'oredi': 597,\n",
              " 'bill': 598,\n",
              " 'case': 599,\n",
              " 'congratulation': 600,\n",
              " 'park': 601,\n",
              " 'read': 602,\n",
              " 'light': 603,\n",
              " 'return': 604,\n",
              " '150pmsg': 605,\n",
              " '08000839402': 606,\n",
              " 'project': 607,\n",
              " 'th': 608,\n",
              " '10': 609,\n",
              " 'nope': 610,\n",
              " 'outside': 611,\n",
              " 'fri': 612,\n",
              " 'pretty': 613,\n",
              " 'sea': 614,\n",
              " 'tsampcs': 615,\n",
              " 'drug': 616,\n",
              " 'lovely': 617,\n",
              " 'wkly': 618,\n",
              " '12': 619,\n",
              " 'hungry': 620,\n",
              " 'confirm': 621,\n",
              " 'whole': 622,\n",
              " 'frnds': 623,\n",
              " 'quiz': 624,\n",
              " 'youll': 625,\n",
              " 'youve': 626,\n",
              " 'course': 627,\n",
              " 'mrng': 628,\n",
              " 'darlin': 629,\n",
              " 'goodmorning': 630,\n",
              " '10p': 631,\n",
              " 'meant': 632,\n",
              " 'fix': 633,\n",
              " 'cd': 634,\n",
              " 'unlimited': 635,\n",
              " 'jay': 636,\n",
              " 'bout': 637,\n",
              " 'rock': 638,\n",
              " 'ten': 639,\n",
              " 'suppose': 640,\n",
              " 'scream': 641,\n",
              " 'cum': 642,\n",
              " 'term': 643,\n",
              " 'kid': 644,\n",
              " 'snow': 645,\n",
              " 'opt': 646,\n",
              " 'â\\x80°ã\\x9b': 647,\n",
              " 'b4': 648,\n",
              " 'gal': 649,\n",
              " 'understand': 650,\n",
              " 'wrong': 651,\n",
              " 'promise': 652,\n",
              " 'turn': 653,\n",
              " 'catch': 654,\n",
              " 'almost': 655,\n",
              " 'etc': 656,\n",
              " 'hee': 657,\n",
              " '0800': 658,\n",
              " 'shower': 659,\n",
              " 'computer': 660,\n",
              " 'mah': 661,\n",
              " 'felt': 662,\n",
              " 'tire': 663,\n",
              " 'joy': 664,\n",
              " 'march': 665,\n",
              " 'side': 666,\n",
              " 'tel': 667,\n",
              " 'fr': 668,\n",
              " '87066': 669,\n",
              " 'dnt': 670,\n",
              " 'single': 671,\n",
              " 'fone': 672,\n",
              " 'bslvyl': 673,\n",
              " 'reading': 674,\n",
              " 'txts': 675,\n",
              " 'figure': 676,\n",
              " 'currently': 677,\n",
              " 'moment': 678,\n",
              " 'forward': 679,\n",
              " 'motorola': 680,\n",
              " 'slow': 681,\n",
              " 'couple': 682,\n",
              " 'as': 683,\n",
              " 'pm': 684,\n",
              " 'savamob': 685,\n",
              " 'sub': 686,\n",
              " 'within': 687,\n",
              " '2003': 688,\n",
              " '800': 689,\n",
              " 'yar': 690,\n",
              " 'happiness': 691,\n",
              " 'area': 692,\n",
              " 'ã¥â£350': 693,\n",
              " 'paper': 694,\n",
              " 'sex': 695,\n",
              " 'mayb': 696,\n",
              " 'wats': 697,\n",
              " 'murder': 698,\n",
              " 'least': 699,\n",
              " 'earlier': 700,\n",
              " 'film': 701,\n",
              " 'chennai': 702,\n",
              " 'gas': 703,\n",
              " 'wasnt': 704,\n",
              " 'freemsg': 705,\n",
              " 'reward': 706,\n",
              " 'eh': 707,\n",
              " 'national': 708,\n",
              " 'eg': 709,\n",
              " 'fall': 710,\n",
              " 'cheer': 711,\n",
              " 'crave': 712,\n",
              " 'hospital': 713,\n",
              " 'wow': 714,\n",
              " 'correct': 715,\n",
              " 'pas': 716,\n",
              " 'complimentary': 717,\n",
              " 'load': 718,\n",
              " 'askd': 719,\n",
              " 'direct': 720,\n",
              " 'ni8': 721,\n",
              " 'hell': 722,\n",
              " 'mr': 723,\n",
              " 'semester': 724,\n",
              " 'laptop': 725,\n",
              " 'blue': 726,\n",
              " 'swing': 727,\n",
              " 'christmas': 728,\n",
              " 'via': 729,\n",
              " '1000': 730,\n",
              " 'small': 731,\n",
              " '150': 732,\n",
              " 'ago': 733,\n",
              " 'st': 734,\n",
              " 'chikku': 735,\n",
              " 'rental': 736,\n",
              " 'tc': 737,\n",
              " 'remove': 738,\n",
              " 'ipod': 739,\n",
              " 'gym': 740,\n",
              " 'train': 741,\n",
              " 'darren': 742,\n",
              " 'an': 743,\n",
              " 'eye': 744,\n",
              " 'store': 745,\n",
              " 'ugh': 746,\n",
              " 'extra': 747,\n",
              " 'knew': 748,\n",
              " 'photo': 749,\n",
              " 'fill': 750,\n",
              " 'support': 751,\n",
              " 'p': 752,\n",
              " 'information': 753,\n",
              " 'surprise': 754,\n",
              " 'grin': 755,\n",
              " 'luck': 756,\n",
              " 'write': 757,\n",
              " 'difficult': 758,\n",
              " 'john': 759,\n",
              " 'father': 760,\n",
              " 'comp': 761,\n",
              " 'usf': 762,\n",
              " 'request': 763,\n",
              " 'copy': 764,\n",
              " 'link': 765,\n",
              " 'comin': 766,\n",
              " 'abiola': 767,\n",
              " 'xx': 768,\n",
              " 'stand': 769,\n",
              " 'loan': 770,\n",
              " 'page': 771,\n",
              " 'txting': 772,\n",
              " 'wine': 773,\n",
              " 'safe': 774,\n",
              " 'muz': 775,\n",
              " 'bath': 776,\n",
              " 'wed': 777,\n",
              " 'deal': 778,\n",
              " 'complete': 779,\n",
              " 'orchard': 780,\n",
              " 'kate': 781,\n",
              " 'register': 782,\n",
              " 'teach': 783,\n",
              " 'expect': 784,\n",
              " 'lover': 785,\n",
              " 'disturb': 786,\n",
              " 'wana': 787,\n",
              " 'sim': 788,\n",
              " 'somebody': 789,\n",
              " 'discount': 790,\n",
              " 'india': 791,\n",
              " 'hmm': 792,\n",
              " 'fight': 793,\n",
              " 'rent': 794,\n",
              " 'lady': 795,\n",
              " 'warm': 796,\n",
              " 'door': 797,\n",
              " 'idea': 798,\n",
              " 'whenever': 799,\n",
              " 'truth': 800,\n",
              " 'heard': 801,\n",
              " 'frm': 802,\n",
              " 'cancel': 803,\n",
              " 'fantasy': 804,\n",
              " 'fact': 805,\n",
              " 'slowly': 806,\n",
              " 'hr': 807,\n",
              " 'nah': 808,\n",
              " 'callertune': 809,\n",
              " 'press': 810,\n",
              " 'info': 811,\n",
              " 'wap': 812,\n",
              " 'england': 813,\n",
              " 'child': 814,\n",
              " 'oops': 815,\n",
              " 'joke': 816,\n",
              " 'situation': 817,\n",
              " 'short': 818,\n",
              " 'rply': 819,\n",
              " 'representative': 820,\n",
              " 'men': 821,\n",
              " 'quote': 822,\n",
              " 'del': 823,\n",
              " 'lovable': 824,\n",
              " 'pray': 825,\n",
              " 'spend': 826,\n",
              " 'waste': 827,\n",
              " 'trust': 828,\n",
              " 'bathe': 829,\n",
              " 'bcoz': 830,\n",
              " 'road': 831,\n",
              " 'kick': 832,\n",
              " 'admirer': 833,\n",
              " 'deep': 834,\n",
              " 'leaf': 835,\n",
              " 'hmv': 836,\n",
              " 'stupid': 837,\n",
              " 'somewhere': 838,\n",
              " 'immediately': 839,\n",
              " 'din': 840,\n",
              " 'met': 841,\n",
              " 'ex': 842,\n",
              " 'woke': 843,\n",
              " 'mm': 844,\n",
              " 'yep': 845,\n",
              " 'voice': 846,\n",
              " 'ldn': 847,\n",
              " 'ure': 848,\n",
              " 'different': 849,\n",
              " 'style': 850,\n",
              " 'monday': 851,\n",
              " 'water': 852,\n",
              " 'opinion': 853,\n",
              " 'less': 854,\n",
              " 'member': 855,\n",
              " 'across': 856,\n",
              " 'cheap': 857,\n",
              " 'em': 858,\n",
              " 'ho': 859,\n",
              " 'gap': 860,\n",
              " 'fantastic': 861,\n",
              " 'glad': 862,\n",
              " 'summer': 863,\n",
              " 'gettin': 864,\n",
              " 'reveal': 865,\n",
              " 'poor': 866,\n",
              " 'asap': 867,\n",
              " 'otherwise': 868,\n",
              " 'ntt': 869,\n",
              " '10pmin': 870,\n",
              " 'convey': 871,\n",
              " 'regard': 872,\n",
              " 'doctor': 873,\n",
              " 'who': 874,\n",
              " 'energy': 875,\n",
              " 'doin': 876,\n",
              " 'excuse': 877,\n",
              " 'med': 878,\n",
              " 'empty': 879,\n",
              " 'std': 880,\n",
              " '11': 881,\n",
              " 'seriously': 882,\n",
              " 'mark': 883,\n",
              " 'worried': 884,\n",
              " 'sick': 885,\n",
              " 'forever': 886,\n",
              " 'bos': 887,\n",
              " 'specially': 888,\n",
              " 'flight': 889,\n",
              " 'inform': 890,\n",
              " 'buying': 891,\n",
              " 'sunshine': 892,\n",
              " 'sony': 893,\n",
              " 'lazy': 894,\n",
              " 'lect': 895,\n",
              " 'completely': 896,\n",
              " 'hmmm': 897,\n",
              " 'lift': 898,\n",
              " 'especially': 899,\n",
              " 'mrt': 900,\n",
              " 'appreciate': 901,\n",
              " 'flirt': 902,\n",
              " 'unless': 903,\n",
              " 'tease': 904,\n",
              " 'sport': 905,\n",
              " 'accept': 906,\n",
              " 'ã¥â£200': 907,\n",
              " 'normal': 908,\n",
              " 'rest': 909,\n",
              " '11mths': 910,\n",
              " 'merry': 911,\n",
              " 'pete': 912,\n",
              " 'record': 913,\n",
              " 'access': 914,\n",
              " 'round': 915,\n",
              " 'urself': 916,\n",
              " 'bluetooth': 917,\n",
              " 'reference': 918,\n",
              " 'brings': 919,\n",
              " 'mistake': 920,\n",
              " '50': 921,\n",
              " 'kinda': 922,\n",
              " 'result': 923,\n",
              " 'optout': 924,\n",
              " 'meh': 925,\n",
              " 'near': 926,\n",
              " 'silent': 927,\n",
              " 'fat': 928,\n",
              " 'hotel': 929,\n",
              " 'hurry': 930,\n",
              " 'noon': 931,\n",
              " 'â\\x80°ã\\x9bã\\x92': 932,\n",
              " 'xy': 933,\n",
              " 'no1': 934,\n",
              " 'wwwgetzedcouk': 935,\n",
              " 'aint': 936,\n",
              " 'bid': 937,\n",
              " 'charity': 938,\n",
              " 'tampa': 939,\n",
              " 'user': 940,\n",
              " 'sale': 941,\n",
              " 'gay': 942,\n",
              " 'wear': 943,\n",
              " 'ã¥â£800': 944,\n",
              " 'nyt': 945,\n",
              " 'hiya': 946,\n",
              " 'deliver': 947,\n",
              " 'nobody': 948,\n",
              " 'mode': 949,\n",
              " 'others': 950,\n",
              " 'bb': 951,\n",
              " 'frens': 952,\n",
              " 'tht': 953,\n",
              " 'share': 954,\n",
              " '2nite': 955,\n",
              " 'list': 956,\n",
              " 'thinkin': 957,\n",
              " 'flag': 958,\n",
              " 'colleague': 959,\n",
              " 'cup': 960,\n",
              " 'entitle': 961,\n",
              " 'anymore': 962,\n",
              " 'sunday': 963,\n",
              " '87077': 964,\n",
              " 'pizza': 965,\n",
              " 'quick': 966,\n",
              " 'learn': 967,\n",
              " 'roommate': 968,\n",
              " 'letter': 969,\n",
              " 'youd': 970,\n",
              " 'nigeria': 971,\n",
              " 'ice': 972,\n",
              " 'cinema': 973,\n",
              " 'spent': 974,\n",
              " 'trouble': 975,\n",
              " 'planning': 976,\n",
              " 'ave': 977,\n",
              " 'apartment': 978,\n",
              " 'inc': 979,\n",
              " '2004': 980,\n",
              " 'bother': 981,\n",
              " 'bak': 982,\n",
              " 'dvd': 983,\n",
              " 'sometimes': 984,\n",
              " 'goto': 985,\n",
              " 'wheres': 986,\n",
              " 'freephone': 987,\n",
              " 'however': 988,\n",
              " 'settle': 989,\n",
              " 'dead': 990,\n",
              " 'slept': 991,\n",
              " 'file': 992,\n",
              " 'star': 993,\n",
              " 'sign': 994,\n",
              " 'street': 995,\n",
              " 'ufind': 996,\n",
              " 'rreveal': 997,\n",
              " 'specialcall': 998,\n",
              " 'goodnight': 999,\n",
              " 'lem': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azdQlRpGne-2",
        "outputId": "a4478011-01ab-4cc7-9808-d0019252e533"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "\n",
        "train_part= int(len(text)*0.7)\n",
        "train_X, test_X =sequences[:train_part], sequences[train_part:]\n",
        "\n",
        "train_X.shape,test_X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3900,), (1672,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1hOdFkZnnqf",
        "outputId": "089e00fd-52ec-417b-ee70-96a79ed4a215"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len = 30\n",
        "#transforms a list (of length num_samples) of sequences (lists of integers) \n",
        "#into a 2D Numpy array of shape (num_samples, num_timesteps) num_timesteps is the maxlen argument.\n",
        "train_X_pad = pad_sequences(train_X, maxlen=max_len)\n",
        "test_X_pad = pad_sequences(test_X, maxlen=max_len)\n",
        "print(train_X_pad.shape)\n",
        "print(test_X_pad.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3900, 30)\n",
            "(1672, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxbixWgHMxZx",
        "outputId": "8da77427-7b55-469f-d767-35a640acdd97"
      },
      "source": [
        "train_X_pad[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    4, 3814,  280,  577,  543, 1059,   44,   62,\n",
              "        250, 1060,   94, 2539, 1061,    2, 3815,   77], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHzGfNa3M2ZO",
        "outputId": "7a0dc34e-42d2-4417-c13d-91c120dc5b6f"
      },
      "source": [
        "train_X[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 3814, 280, 577, 543, 1059, 44, 62, 250, 1060, 94, 2539, 1061, 2, 3815, 77]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seYiv-0Lo4ON",
        "outputId": "b33554e0-1506-4c92-bbdc-0d5a5eb8684e"
      },
      "source": [
        "#We need to know the size of the vocabulary for defining the embedding layer.\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR5MUYGjn6JQ",
        "outputId": "395b7fb0-df38-4f8a-e873-e1be4e39647b"
      },
      "source": [
        "# create the model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input,Embedding,LSTM,Dense\n",
        "\n",
        "def generate_model(vocab_size,max_len,embedding_size):\n",
        "\n",
        "  _input = Input(max_len)\n",
        "\n",
        "  x = Embedding(input_dim = vocab_size, output_dim = embedding_size, input_length=max_len) (_input)\n",
        "\n",
        "  x = LSTM(100)(x)\n",
        "\n",
        "  output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = Model(inputs= [_input], outputs = [output])\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "  \n",
        "\n",
        "model = generate_model(vocab_size,max_len,embedding_size=50)\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(train_X_pad, trainY, epochs=10, batch_size=60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 30, 50)            421450    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               60400     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 481,951\n",
            "Trainable params: 481,951\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "65/65 [==============================] - 4s 36ms/step - loss: 0.4416 - accuracy: 0.8466\n",
            "Epoch 2/10\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0977 - accuracy: 0.9771\n",
            "Epoch 3/10\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0239 - accuracy: 0.9948\n",
            "Epoch 4/10\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0160 - accuracy: 0.9965\n",
            "Epoch 5/10\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0088 - accuracy: 0.9977\n",
            "Epoch 6/10\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0026 - accuracy: 0.9999\n",
            "Epoch 7/10\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 6.4999e-04 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Epoch 9/10\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 0.0015 - accuracy: 0.9991\n",
            "Epoch 10/10\n",
            "65/65 [==============================] - 2s 36ms/step - loss: 3.5331e-04 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_ZpTYbpou_1",
        "outputId": "ea31bb4e-a9fd-480b-de12-055c4886144a"
      },
      "source": [
        "pred_test = model.predict(test_X_pad)\n",
        "#pred_test = np.argmax(pred_test,axis=1)\n",
        "pred_test = pred_test.round()\n",
        "\n",
        "#print evaluation metrics \n",
        "print(classification_report(testY,pred_test))\n",
        "print(confusion_matrix(testY,pred_test))\n",
        "print(\"Accuracy:\",accuracy_score(testY, pred_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      1444\n",
            "           1       0.98      0.92      0.95       228\n",
            "\n",
            "    accuracy                           0.99      1672\n",
            "   macro avg       0.98      0.96      0.97      1672\n",
            "weighted avg       0.99      0.99      0.99      1672\n",
            "\n",
            "[[1439    5]\n",
            " [  19  209]]\n",
            "Accuracy: 0.9856459330143541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8HanS1qYwbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9aec759-eee7-4045-b550-5db4706a3019"
      },
      "source": [
        "pred_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0964839e-04],\n",
              "       [1.8012886e-05],\n",
              "       [1.6417334e-05],\n",
              "       ...,\n",
              "       [5.9005618e-04],\n",
              "       [4.3566601e-05],\n",
              "       [2.1302700e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5a0jlwzOmMW",
        "outputId": "39836673-f667-4446-9c73-73320efbc74d"
      },
      "source": [
        "pred_test.round()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbhBM79pOxAy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}